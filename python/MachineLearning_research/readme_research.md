## MachineLearning_research
> バージョン<br>
Python 3.8.3<br>
> 使用ライブラリ<br>
requests, base64, pandas, numpy, scikit-learn, xgbppst <br>
## ファイルの説明
- 1_label.py<br>
Google Cloudが提供するVisionAPIに写真をリクエストし，レスポンスをユーザーごとjsonファイルに保存することを自動で行います．<br>
料金が1リクエスト当たりかかること，1リクエストで16枚まで写真を送信できることなどを考え，無駄なく効率的に単語に変換できるようなプログラムにしました．<br>
json形式で単語のみを抽出しようとしましたが，当時エラーが出て対応に時間がかかりそうであったため，レスポンスをすべてまとめてそこから抽出するようなシステムとしました．<br>
この段階では，単語ごと「付与されるID，文字列，予測確率」と3つの情報が入っています．<br>
- 2_Makecsv.py<br>
前項で作成したjsonファイルから単語と予測確率のみ抽出します．<br>
csvにまとめる際，写真毎にどのような単語が出たか調べたい目的があったため，写真が切り替わるごとに改行するようなプログラムにしました．<br>
ユーザー単位でcsvファイルが作成され，単語のデータが格納されます．<br>
- 3_MakeVector.py<br>
作成したcsvファイルを基に，単語を特徴量としたデータセットを作成します．<br>
この段階で参照するディレクトリには，トレーニングデータの正例と負例，テストデータの被験者をまとめ，データセット内にすべてまとめるようにしました．<br>
- 4_SyumiIdent_example.py<br>
データセットを読み込み，トレーニングデータとテストデータに分割した後に5分割交差検証を行います．<br>
学習するにあたって，データセットは出現頻度をそのまま使うだけではなく正規化を行ったり，パラメータチューニングを行ったりして最適な学習はどれかを確認することを行いました．<br>
今回は代表として，データセットを最小値0，最大値1に収め，パラメータチューニングなしで機械学習を行ったケースを掲載しました．<br>
データセット中で趣味が該当する人数が該当しない人数に対して2%程度とかなり少なく，既存の正解率では該当しない人の予測に値が引っ張られてしまいました．<br>
その中でも，正例の正解数と負例の正解数は同程度に必要な情報でした．<br>
そこで，「正例のうちどれだけ正解したか」と「負例のうちどれだけ正解したか」の2つの数値を平均した値を独自の正解率として実装し，この値を使って性能評価しました．<br>
